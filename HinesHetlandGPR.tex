\documentclass[10pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{arydshln}
\usepackage{bm}
\title{Revealing Transient Strain in Geodetic Data with the Radial Basis Function Finite Difference Method}
\author{Trever T. Hines and Eric A. Hetland}

% OUTLINE
% INTRODUCTION
% - Why we care about strain in the crust
%   - Knowing long term strain rates tells us where we can expect seismicity
%
% - How people have gone about estimating strain rates
%   - Draw distinction between parametric and nonparametric methods
%   - Draw distinction between model based and data based parametric methods 
%   - Talk about Kato
%
% - Another, more challenging problem is how to calculate time-dependent strain
%   - Time dependent strain rates could illuminate transient geophysical signals such as postseismic deformation, 
%	  slow slip events, or volcanic deformation. 	  
%	- Since numerous megathrust earthquakes were preceded by slow slip, it is important to detect these features.
%	- We can also use estimates of transient strain to calibrate strain meters.	
%	- People who have tackled this problem before include Ohtani and Holt.	
%	- A major deficiency with these methods is that they are parametric giving poor uncertainties. Without good 
%	  uncertainties we cannot objectively discern signal from noise and we cannot calibrate BSM.	
% - Here we propose GPR and we tackle several two major difficulties	
%   - The method is similar to an extension of Kato to the time domain. We address two debilitating difficulties that 
%     arise. We also dont do that autocovariance bullshit.  Instead we use REML.  
%	- outliers  
%	- dense matrix
%	
% - GPR can be used for more than just estimating strain and it is a powerful geophysical tool. We can use it to quantify
%   spatial noise in GPS data. (this should be a side blurb when talking about quantifying signal.   
%
% - We discuss the method, form prior with REML, and demonstrate utility in detecting SSE by comparing it to tremor.	  
%
% METHODS
% - define model
% - discuss known deficiencies with the model
% - describe covariance as a time-space separable function 
% - describe geophysically relevant gaussian processes. (include seasonal and spherical)
% - REML for determining optimal hyperparameters
% - conditioning the prior with observations
% - differentiating the Gaussian process
% - note on addition, subtraction, and scaling
% - REML
% - Numerical notes
%   - partition inverse and solve with CHOLMOD
%
% APPLICATION TO CASCADIA SSE
% - SSE background
% - REML results
%   - noise 
%   - signal for IBM, SE, and WEN
%   - Plot all covariances functions

% - Strain results
%   - map view plot
%   - time series plot

% CONCLUSION
% - future work
% - additional applications other than sse. Discuss potential use for noise modeling


\begin{document}

\maketitle


\section{Introduction}\label{sec:Introduction}

Crustal strain rates are fundamentally important quantities for assessing seismic hazard, since knowing where and how quickly strain is accumulating gives insight into where we can expect stored elastic energy to be released seismically.  It is then important to develop and improve upon methods for mapping strain in tectonically active regions because such maps could conceivably feed into seismic hazard models such as UCERF3 \citep{Field2014}. 

Methods for estimating strain from geodetic data fall in one of two categories.  There are model-based approaches which assume that strain is the result of loading on faults which have a known geometry, and there are data-based approaches which make no assumptions about the source of deformation.  We will exclusively consider data-based approaches in this paper.  The classic and simplest method for estimating strain is to assume that the strain rate is constant in time and spatially uniform within subnetworks of the geodetic data.  Linear least squares is then used to find the components of the strain rate tensor for each subnetwork \citep[e.g][]{Frank1966,Prescott1976,Savage1986,Feigl1990,Murray2000}. Several algorithms have been developed to improve upon this procedure. \citet{Shen1996} and \citet{Shen2015} discuss an algorithm where, instead of using the immediately adjacent stations to calculate strain at a position, the strain is computed with a weighted average over the entire network where the weighting is smaller for more distant stations.  Another strategy is to fit a set of interpolating basis functions to the deformation field and then compute the strain from the analytical derivative of the interpolant \citep[e.g.][]{Beavan2001,Tape2009,Sandwell2016}.  

The aforementioned studies have all been concerned with estimating long term strain rates. Time dependent strain would be useful for studying geophysical processes which occur over timescales of days to years such as slow slip events, postseismic relaxation, or volcanic deformation.  \citet{Ohtani2010} identified transient strain events by fitting a set of spatial wavelet basis functions to the deformation field at discrete time epochs, and a Kalman filtering strategy was used to ensure that the coefficients for each basis function varied smoothly in time. \citet{Holt2013} calculated time dependent strain by differentiating a bicubic interpolant that was fit to each epoch of a temporally smoothed deformation field. 

Each of the methods described above are designed to overcome two complications that arise in estimating deformation gradients: (1) geodetic data are noisy and differentiation will only amplify the noise and (2) geodetic data are not observed on a regular grid, which prevents the use of standard finite difference methods for computing derivatives. In this paper we demonstrate that both of these complications can be elegantly handled with the Radial Basis Function-Finite Difference (RBF-FD) method.  

The RBF-FD method was developed simultaneously and independently by \citet{Tolstykh2003}, \citet{Shu2003}, \citet{Cecil2004}, and \citet{Wright2006} as a computationally efficient way to solve large scale partial differential equations over irregular, multi-dimensional domains.  The RBF-FD method can be thought of as a generalization of the traditional finite difference method, where the node layout is no longer restricted to regular grids. Indeed, the RBF-FD method can be used to estimate derivates of discrete data located at arbitrary scattered positions in multi-dimensional space.  The RBF-FD method is particularly appealing because it is algorithmically simple, regardless of the domain shape or node layout, and also because the method has performed well in numerous benchmark tests \citep[and references therein]{Fornberg2015}.

In this paper, we do not use the RBF-FD method to solve a partial differential equation, but rather we use it to spatially smooth geodetic data and to compute deformation gradients. Our smoothing strategy can be viewed as a non-parametric, low-pass filter for scattered data where the degree of smoothness is controlled by a user specifies cutoff frequency. This can be contrasted with interpolation based methods where the resulting interpolant can be largely and perhaps unpredictably controlled by the choice of basis function. This process of smoothing and differentiating can be extended to estimate time dependent strain rates.  In that case, we first temporally smooth and differentiate GPS displacement time series to get time dependent velocities.  We then spatially smooth and differentiate the resulting velocities for each time epoch to get time dependent strain rates.  

The method proposed in this paper has numerous advantages which set it apart from other methods for computing strain rates. The method is computationally efficient and stable (there is no inversion of an ill-conditioned matrix).  There are no hyper parameters or penalty parameters that need to be tuned for each application.  As opposed to interpolation strategies such as \citet{Beavan2001}, \citet{Tape2009}, or \citet{Ohtani2010}, our method assumes that velocities are locally rather than globally continuous, which allows us to easily handle discontinuities resulting from, for example, a creeping fault. 

We begin this paper by summarizing the RBF-FD scheme and explaining how we construct differentiation matrices for scattered data. We then introduce the RBF-FD filter, which is used to smooth the observed geodetic data prior to differentiation.  We provide two real world demonstraitions of our method for calculating strain rates.  First we calculate the long term strain rates in Southern California from the CMM3 velocity data set \citep{Shen2011}, and we verify that our results are consistent with other studies. We then calculate time dependent strain rates in Cascadia from the GPS data provided by UNAVCO.  In Cascadia, we analyze strain resulting from slow slip events and compare it to the long term tectonic strain accumulation. Slow slip events are found to produce compression in the Olympic Peninsula, which is in addition to the compression resulting from tectonic loading.  Further south in Oregon, the slow slip events tend to release the compressional strain that is accumulated tectonically.  While similar conclusions have been drawn from fault slip inversions for slow slip events, it is important to recognize that slip inversion are the product of inverting an ill-conditioned matrix making it difficult to determine whether slip inferences are real or just an artifact of the inversion.  The strain rates presented in this paper are more direct observations and can be interpretted with a higher degree of confidence. 

\section{Method}\label{sec:Method}

In this section, we describe how GNSS displacement observations are used to identify transient crustal strain rates, which we denote as $\dot{\bm{\varepsilon}}(x,t)$. We consider $\dot{\bm{\varepsilon}}$ to be spatially and temporally coherent deviations from the steady rate of strain accumulation from plate tectonics. We determine $\dot{\bm{\varepsilon}}$ by first identifying transient displacements, $\bm{u}(x,t)$, which we then spatially and temporally differentiate.  As we will show in Section X, estimates of $\dot{\bm{\varepsilon}}$ turn out to be more effective at illuminating geophysical signal than estimates of $\bm{u}$ or $\dot{\bm{u}}$.  We make a prior assumption that each component of $\mathbf{u}$ is a three-dimensional (two spatial dimensions and time) Gaussian process,
\begin{equation}\label{eq:TransientDeformation}
u_i(x,t) \sim \mathcal{N}\left(0,C_{u_i}\right),
\end{equation}
where $C_{u_i}(x,t;x',t')$ is a covariance function indicating how we expect $u_i(x,t)$ to covary with $u_i(x',t')$. For simplicity, we treat each component of displacement independently and ignore any potential covariance. We then drop the component subscripts with the understanding that the same analysis is being repeated to estimate the east, north, and vertical components of $\bm{u}$. We further assume that $C_u$ can be separated into positive definite spatial and temporal functions as 
\begin{equation}\label{eq:TransientCovariance}
C_{u}(x,t;x',t') = X(x,x')T(t,t').
\end{equation}  
The appropriate choice for $X$ and $T$ may vary depending on the geophysical signal we are trying to describe (e.g. postseismic deformation or deformation from slow slip events), and we discuss this matter in the next section.  

\subsection{Spatial and temporal covariance functions}
In this section, we list several covariance functions which are considered in this paper or could be of use in future studies. For see \citet{Rasmussen2006} for additional information.   

The squared exponential covariance function,
\begin{equation}\label{eq:SE}
C(x,x') = \alpha^2 \exp\left(\frac{-||x - x'||_2^2}{2 \beta^2}\right),
\end{equation}
is commonly used in Kriging \citep[e.g,][]{Cressie1992} and Gaussian process regression \citep[e.g.,][]{Rasmussen2006}.  The squared exponential is a valid (i.e. positive definite) covariance function for any number of spatial dimensions, and it describes an isotropic Gaussian processes with realizations that are infinitely differentiable.  \citet{Kato1998} demonstrated that eq. (\ref{eq:SE}) is an appropriate covariance model for describing long-term tectonic strain rates.  

The Wendland class of covariance functions \citep{Wendland2005} are positive definite in $\mathbb{R}^d$, and they describes an isotropic Gaussian process with realizations that can be differentiated $k$ times. The form of the covariance function depends on the choice of $d$ and $k$. Wendland covariance functions have compact support, which is a particularly useful property because we can exploit the sparsity of the the corresponding covariance matrices. In this study we use Wendland covariance functions to describe the temporal component of transient displacements. Therefore, we only require that $d=1$ and $k=1$. The corresponding Wendland covariance function is 
\begin{equation}\label{eq:Wendland}
C(x,x') = \alpha^2\left(1 - \frac{|x - x'|}{\beta}\right)^3_+ \left(\frac{3|x - x'|}{\beta} + 1\right), \ \ \ x \in \mathbb{R}^1,
\end{equation}
where
\begin{equation}
(x)_+ = 
\begin{cases}
x, \ \ \ x > 0 \\
0, \ \ \ \mathrm{otherwise}.
\end{cases}
\end{equation}

They are positive definite for a finite dimensional space and are finitely differentiable.  If the length-scale is sufficiently small then we can take advantage of the sparsity of the covariance matrices in Section X. This turns out to significantly increase scale of the problems which can be addressed in this analysis.

FOGM solves the differential equation .... Has been used by Langbein.

Valid in ND

Brownian Motion is the solution to the differential equation .... Has been used by Langbein to describe noise
Valid in 1D

Integrated Brownian motion solves ... . It has been used by Segall to describe slip, Ohatani, Murray, 
Valid in 1D

We also want to give notable mention to the Periodic covariance function


\subsection{Constraining displacements and strain with GNSS data}
We constrain $u$ with GNSS data, which records $u$ as well as other physical and non-physical processes which we are not interested in. We describe GNSS data, $\bm{d}_*$, as the realization of a random vector $\bm{d} = [d_{ij}]^T$, where $d_{ij}$ describes observations at position $x_i$ and time $t_j$. We assume that the observations can be described as   
\begin{align}\label{eq:Data}
d_{ij} = &u(x_i,t_j) + \epsilon(x_i,t_j) + a_{i} + b_{i} t_j + \\
         &c_{1i}\sin(2 \pi t_j) + c_{2i}\cos(2 \pi t_j) + c_{3i}\sin(4 \pi t_j) + c_{4i}\cos(4 \pi t_j), 
\end{align}
where $a_i$ is an offset that is unique for each GNSS monument, $b_i$ is the steady rate of tectonic deformation at $x_i$, the sinusoids describe seasonal deformation (using units of years for $t$), and $\epsilon$ is a Gaussian process for noise that cannot be described parametrically. $\epsilon$ can consist of white noise, temporally correlated noise describing benchmark wobble \citep[e.g.,][]{Wyatt1982,Wyatt1989}, or spatially correlated noise describing common mode error \citep[e.g.,][]{Wdowinski1997}.  For now, we describe $\epsilon$ generally as $\epsilon \sim \mathcal{N}(0,C_d)$. We consider the coefficients $a_{i}$, $b_{i}$, and $c_{kj}$, to be unknown and uncorrelated random variables. Of course, the tectonic deformation, $b_i$, is in reality spatially correlated and we could invoke tectonic model to form a prior on $b_i$. However, in our application to Cascadia, we will be using displacement time series which are long enough to sufficiently constrain $b_i$ for each station and there is no need to incorporate a prior. Likewise, the seasonal coefficients may be spatially correlated as suggested by Langbein2008?. It may be worth exploring and exploiting such a correlation in a future study.       
     
Optimal Hyperparameters

Conditioning the GP

Differentiation, scaling and addition to get strain     

\subsection{Time Depenent Strain Rate in Cascadia}\label{sec:ApplicationsCascadia}

BACKGROUND

\citet{Dragert2001} first discovered slow slip events

Slow slip event depths from \citet{Dragert2001}, \citet{Wech2009}, \citet{Schmidt2010}, \citet{Bartlow2011} show slip concentrated at depths from 30 to 50 km detph.
 
Interseismic locking depths from \citet{Fluck1997}, \citet{Murray2000}, \citet{McCaffrey2007} and \citet{McCaffrey2013}, \citet{Burgette2009}, \citet{schmalzle2014} are consistent with a full locking down to about 20 km.

%Studies which simultaneously looked at intersesimic and ets are \citet{Holtkamp2010} and \citet{Schmalzle2014}
Studies which simultaneously modeled interseismic and ets are \citet{Holtkamp2010} and \citet{schmalzle2014}

METHOD

We use GPS displacement time series to make daily estimates of strain rates from 2010-01-01 to 2016-07-01 in the Pacific Northwest.  Our method consists of two distinct steps; we temporally smooth and differentiate the displacement time series for each station, and then we spatially smooth and differentiate the velocity field for each day.  We temporally smooth the GPS displacements with the method described in \ref{sec:Filter}, and we treat days with missing data as observations with infinite uncertainty. As noted above, this is effectively equivalent to fitting a smoothing spline to each time series, which can also be efficiently done with a Kalman filtering strategy \citep{Kohn1987}.  We chose a cutoff frequency of ZZZ, which is high enough to acurately describe deformation during a slow slip event.  Spatial smoothing is done with the RBF-FD filter and differentiation to get the strain rates was done with the RBF-FD scheme.  We picked a cutoff frequency of XXX for smoothing.

\section{Discussion and Conclusion}\label{sec:Discussion}
% discuss potential applications for slip models

% discuss how we remove errors like reference frame and seasonals

% discuss how this can be used for tikhonov regularization

% we do not interpolate the strain field because it may introduce spurious artifacts Baxter2011

% Discuss similarities with PCA used in Dong2006 and common mode error by Wdowinski1997
% note that these errors are due to long wavelength features which get removed in strain calculations!!!
% see strain method by almendinger2007

% mention the scec geodetic transient exercise Lohman2013 and references therein

% Note that segalls 2016 paper mentions the gap between interseismic and sse

% mention howell2016, who said some crap about verticals, mention Hammond2016 so said more sensible crap about verticals

% note that this can be used for smoothing verticals, and compare it with burgette2009

% change the notation for stencil size or smoothness order because they are both n. use p for smoothness order


The material presented in this paper is primarily focused on GPS data; however, we speculate that the RBF-FD scheme can be of particular use in denoising borehole strain meter (BSM) data.  The Plate Boundary Observatory has deployed X BSMs along the Western United States.  BSM data contains low frequency drift resulting from relaxation of the borehole \citep{Gladwin1987}, which can obscure the geophysical signal of interest.  We suggest that the RBF-FD scheme may be useful in denoising BSM data.  Since the RBF-FD scheme provides a straight-forward mapping from GPS displacements to strain at any target locations, it is possible to use GPS derived strains as \textit{a priori} information for strain at BSM sites. GPS derived strains could then aid in discerning tectonic signal from noise in BSM data.

Additional uses for strain: transient detection, prior for strain meters,  

Additional potential applications of the RBF-FD method: regularizing inverse problems, 

% cite eric calais for triangulation strain

\bibliographystyle{apalike}
\bibliography{mybib}  
 
\end{document}
