\documentclass[10pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{arydshln}
\usepackage{bm}
\title{Revealing Transient Strain in Geodetic Data with the Radial Basis Function Finite Difference Method}
\author{Trever T. Hines and Eric A. Hetland}

% OUTLINE
% INTRODUCTION
% - Why we care about strain in the crust
%   - Knowing long term strain rates tells us where we can expect seismicity
%
% - How people have gone about estimating strain rates
%   - Draw distinction between parametric and nonparametric methods
%   - Draw distinction between model based and data based parametric methods 
%   - Talk about Kato
%
% - Another, more challenging problem is how to calculate time-dependent strain
%   - Time dependent strain rates could illuminate transient geophysical signals such as postseismic deformation, 
%	  slow slip events, or volcanic deformation. 	  
%	- Since numerous megathrust earthquakes were preceded by slow slip, it is important to detect these features.
%	- We can also use estimates of transient strain to calibrate strain meters.	
%	- People who have tackled this problem before include Ohtani and Holt.	
%	- A major deficiency with these methods is that they are parametric giving poor uncertainties. Without good 
%	  uncertainties we cannot objectively discern signal from noise and we cannot calibrate BSM.	
% - Here we propose GPR and we tackle several two major difficulties	
%   - The method is similar to an extension of Kato to the time domain. We address two debilitating difficulties that 
%     arise. We also dont do that autocovariance bullshit.  Instead we use REML.  
%	- outliers  
%	- dense matrix
%	
% - GPR can be used for more than just estimating strain and it is a powerful geophysical tool. We can use it to quantify
%   spatial noise in GPS data. (this should be a side blurb when talking about quantifying signal.   
%
% - We discuss the method, form prior with REML, and demonstrate utility in detecting SSE by comparing it to tremor.	  
%
% METHODS
% - define model
% - discuss known deficiencies with the model
% - describe covariance as a time-space separable function 
% - describe geophysically relevant gaussian processes. (include seasonal and spherical)
% - REML for determining optimal hyperparameters
% - conditioning the prior with observations
% - differentiating the Gaussian process
% - note on addition, subtraction, and scaling
% - REML
% - Numerical notes
%   - partition inverse and solve with CHOLMOD
%
% APPLICATION TO CASCADIA SSE
% - SSE background
% - REML results
%   - noise 
%   - signal for IBM, SE, and WEN
%   - Plot all covariances functions

% - Strain results
%   - map view plot
%   - time series plot

% CONCLUSION
% - future work
% - additional applications other than sse. Discuss potential use for noise modeling


\begin{document}

\maketitle


\section{Introduction}\label{sec:Introduction}

Crustal strain rates are fundamentally important quantities for assessing seismic hazard, since knowing where and how quickly strain is accumulating gives insight into where we can expect stored elastic energy to be released seismically.  It is then important to develop and improve upon methods for mapping strain in tectonically active regions because such maps could conceivably feed into seismic hazard models such as UCERF3 \citep{Field2014}. 

Methods for estimating strain from geodetic data fall in one of two categories.  There are model-based approaches which assume that strain is the result of loading on faults which have a known geometry, and there are data-based approaches which make no assumptions about the source of deformation.  We will exclusively consider data-based approaches in this paper.  The classic and simplest method for estimating strain is to assume that the strain rate is constant in time and spatially uniform within subnetworks of the geodetic data.  Linear least squares is then used to find the components of the strain rate tensor for each subnetwork \citep[e.g][]{Frank1966,Prescott1976,Savage1986,Feigl1990,Murray2000}. Several algorithms have been developed to improve upon this procedure. \citet{Shen1996} and \citet{Shen2015} discuss an algorithm where, instead of using the immediately adjacent stations to calculate strain at a position, the strain is computed with a weighted average over the entire network where the weighting is smaller for more distant stations.  Another strategy is to fit a set of interpolating basis functions to the deformation field and then compute the strain from the analytical derivative of the interpolant \citep[e.g.][]{Beavan2001,Tape2009,Sandwell2016}.  

The aforementioned studies have all been concerned with estimating long term strain rates. Time dependent strain would be useful for studying geophysical processes which occur over timescales of days to years such as slow slip events, postseismic relaxation, or volcanic deformation.  \citet{Ohtani2010} identified transient strain events by fitting a set of spatial wavelet basis functions to the deformation field at discrete time epochs, and a Kalman filtering strategy was used to ensure that the coefficients for each basis function varied smoothly in time. \citet{Holt2013} calculated time dependent strain by differentiating a bicubic interpolant that was fit to each epoch of a temporally smoothed deformation field. 

Each of the methods described above are designed to overcome two complications that arise in estimating deformation gradients: (1) geodetic data are noisy and differentiation will only amplify the noise and (2) geodetic data are not observed on a regular grid, which prevents the use of standard finite difference methods for computing derivatives. In this paper we demonstrate that both of these complications can be elegantly handled with the Radial Basis Function-Finite Difference (RBF-FD) method.  

The RBF-FD method was developed simultaneously and independently by \citet{Tolstykh2003}, \citet{Shu2003}, \citet{Cecil2004}, and \citet{Wright2006} as a computationally efficient way to solve large scale partial differential equations over irregular, multi-dimensional domains.  The RBF-FD method can be thought of as a generalization of the traditional finite difference method, where the node layout is no longer restricted to regular grids. Indeed, the RBF-FD method can be used to estimate derivates of discrete data located at arbitrary scattered positions in multi-dimensional space.  The RBF-FD method is particularly appealing because it is algorithmically simple, regardless of the domain shape or node layout, and also because the method has performed well in numerous benchmark tests \citep[and references therein]{Fornberg2015}.

In this paper, we do not use the RBF-FD method to solve a partial differential equation, but rather we use it to spatially smooth geodetic data and to compute deformation gradients. Our smoothing strategy can be viewed as a non-parametric, low-pass filter for scattered data where the degree of smoothness is controlled by a user specifies cutoff frequency. This can be contrasted with interpolation based methods where the resulting interpolant can be largely and perhaps unpredictably controlled by the choice of basis function. This process of smoothing and differentiating can be extended to estimate time dependent strain rates.  In that case, we first temporally smooth and differentiate GPS displacement time series to get time dependent velocities.  We then spatially smooth and differentiate the resulting velocities for each time epoch to get time dependent strain rates.  

The method proposed in this paper has numerous advantages which set it apart from other methods for computing strain rates. The method is computationally efficient and stable (there is no inversion of an ill-conditioned matrix).  There are no hyper parameters or penalty parameters that need to be tuned for each application.  As opposed to interpolation strategies such as \citet{Beavan2001}, \citet{Tape2009}, or \citet{Ohtani2010}, our method assumes that velocities are locally rather than globally continuous, which allows us to easily handle discontinuities resulting from, for example, a creeping fault. 

We begin this paper by summarizing the RBF-FD scheme and explaining how we construct differentiation matrices for scattered data. We then introduce the RBF-FD filter, which is used to smooth the observed geodetic data prior to differentiation.  We provide two real world demonstraitions of our method for calculating strain rates.  First we calculate the long term strain rates in Southern California from the CMM3 velocity data set \citep{Shen2011}, and we verify that our results are consistent with other studies. We then calculate time dependent strain rates in Cascadia from the GPS data provided by UNAVCO.  In Cascadia, we analyze strain resulting from slow slip events and compare it to the long term tectonic strain accumulation. Slow slip events are found to produce compression in the Olympic Peninsula, which is in addition to the compression resulting from tectonic loading.  Further south in Oregon, the slow slip events tend to release the compressional strain that is accumulated tectonically.  While similar conclusions have been drawn from fault slip inversions for slow slip events, it is important to recognize that slip inversion are the product of inverting an ill-conditioned matrix making it difficult to determine whether slip inferences are real or just an artifact of the inversion.  The strain rates presented in this paper are more direct observations and can be interpretted with a higher degree of confidence. 

\section{Method}\label{sec:Method}

In this section, we describe how GNSS displacement observations are used to identify transient crustal strain rates, which we denote as $\dot{\bm{\varepsilon}}(z)$, where $z$ is the ordered pair $(x,t)$, $x$ are spatial coordinates in $\mathbb{R}^2$, and $t$ is time. We consider $\dot{\bm{\varepsilon}}$ to be spatially and temporally coherent deviations from the steady rate of strain accumulation from plate tectonics. We determine $\dot{\bm{\varepsilon}}$ by first identifying transient displacements, $\bm{u}(z)$, which we then spatially and temporally differentiate.  As we will show in Section X, estimates of $\dot{\bm{\varepsilon}}$ turn out to be more effective at illuminating geophysical signal than estimates of $\bm{u}$ or $\dot{\bm{u}}$.  We make a prior assumption that each component of $\bm{u}$ is a Gaussian process,
\begin{equation}\label{eq:TransientDeformation}
u_i(z) \sim \mathcal{N}\left(0,C_{u_i}\right),
\end{equation}
where $C_{u_i}(z,z')$ is a covariance function indicating how we expect $u_i(z)$ to covary with $u_i(z')$. For simplicity, we treat each component of displacement independently and ignore any potential covariance. We then drop the component subscripts with the understanding that the same analysis is being repeated to estimate the east, north, and vertical components of $\bm{u}$. We further assume that $C_u$ can be separated into positive definite spatial and temporal functions as 
\begin{equation}\label{eq:TransientCovariance}
C_{u}\left((x,t),(x',t')\right) = X(x,x')T(t,t').
\end{equation}  
The appropriate choice for $X$ and $T$ may vary depending on the geophysical signal we are trying to describe (e.g. postseismic deformation or deformation from slow slip events), and we discuss this matter in the next section.  

We constrain $u$ with GNSS data, which records $u$ as well as other physical and non-physical processes which we are not interested in. We describe GNSS observations at position $x_i$ and time $t$ as a realization of the random variable 
\begin{align}\label{eq:Data}
\begin{split}
d_{i}(t) = &u(x_i,t) + \epsilon(x_i,t) + a_{i} + b_{i}t + \\
         &c_{i}\sin(2 \pi t) + q_{i}\cos(2 \pi t) + r_{i}\sin(4 \pi t) + s_{i}\cos(4 \pi t), 
\end{split}
\end{align}
where $a_{i}$ is an offset that is unique for each GNSS monument, $b_{i}$ is the steady rate of tectonic deformation at $x_i$, the sinusoids describe seasonal deformation (using units of years for $t$), and $\epsilon$ is a Gaussian process for noise that cannot be described parametrically.  $\epsilon$ can consist of white noise, temporally correlated noise describing, for example, benchmark wobble \citep[e.g.,][]{Wyatt1982,Wyatt1989}, and/or spatially correlated noise describing, for example, common mode error \citep[e.g.,][]{Wdowinski1997}.  For now, we describe $\epsilon$ generally as $\epsilon \sim \mathcal{N}(0,C_\epsilon)$. We consider the six coefficients in eq. (\ref{eq:Data}) to be uncorrelated random variables distributed as $\mathcal{N}(0,\lambda^2)$ in the limit as $\lambda \to \infty$ (i.e., the coefficients have diffuse priors). Of course, the tectonic deformation, $b_{i}$, is in reality spatially correlated and we could invoke tectonic model to form a prior on $b_{i}$. However, in our application to Cascadia, we will be using displacement time series which are long enough to sufficiently constrain $b_{i}$ for each station and there is no need to incorporate a prior. Likewise, the seasonal coefficients may be spatially correlated as suggested by Langbein2008?. It may be worth exploring and exploiting such a correlation in a future study. 

Let $\bm{y}$ be the set of $(x_i, t)$ pairs describing where and when each of the $n$ GNSS observations have been made. Furthermore, let $\bm{a}$ be the vector of coefficients from eq. (\ref{eq:Data}) for each of the $m$ GNSS monuments, and let $\bm{P}$ be the $n \times 6m$ matrix of corresponding basis functions evaluated at each point in $\bm{y}$. The $n$ GNSS observations, $\bm{d}_*$, are a realization of the random vector
\begin{equation}
\bm{d} = u(\bm{y}) + \epsilon(\bm{y}) + \bm{P}\bm{a},
\end{equation}
which is distributed as $\mathcal{N}(\bm{0},\bm{C_d})$, where
\begin{equation}\label{eq:Cd}
\bm{C_d} = C_u(\bm{y},\bm{y}) + C_\epsilon(\bm{y},\bm{y}) + 
           \lambda^2\bm{P}\bm{P}^T.
\end{equation}
It should be understood that the notation $f(\bm{x})$ and $f(\bm{x},\bm{y})$ is used as shorthand for $[f(x_i)]_{x_i \in \bm{x}}$ and $[f(x_i,y_j)]_{(x_i,y_j) \in \bm{x} \times \bm{y}}$, respectively. In section X, we describe how the observations $\bm{d}_*$ are used to constrain transient displacements $u$ and then for estimates of transient strain rates.



\subsection{Spatial and temporal covariance functions}
We must choose an appropriate Gaussian process describing transient displacements $u$ and GNSS noise $\epsilon$. We assume that $u$ and $\epsilon$ both have zero mean, which leaves for use to select a parameterization for the covariance functions $X$, $T$, and $C_d$.  In this section, we list the covariance functions which are considered in this paper and those which could be of use in future studies. In the following discussion $\alpha$ and $\beta$ are hyperparameters. There are numerous strategies for selecting these hyperparameters (see \citet{Cressie1992}) and we save a discussion on choosing the hyperparameters for Section X.

The squared exponential covariance function,
\begin{equation}\label{eq:SE}
C(x,x') = \alpha^2 \exp\left(\frac{-||x - x'||_2^2}{2 \beta^2}\right),
\end{equation}
is commonly used in Kriging \citep[e.g,][]{Cressie1992} and Gaussian process regression \citep[e.g.,][]{Rasmussen2006}.  The squared exponential is a valid (i.e. positive definite) covariance function for any number of spatial dimensions, and it describes an isotropic (i.e. $C(x,x')$ can be expressed as $\hat{C}(||x - x'||_2)$) Gaussian processes with realizations that are infinitely differentiable.  \citet{Kato1998} and \cite{El-Fiky1999} demonstrated that eq. (\ref{eq:SE}) is an appropriate covariance model for describing long-term tectonic strain rates for Japan.  

The Wendland class of covariance functions \citep{Wendland2005} are positive definite in $\mathbb{R}^d$, and they describes an isotropic Gaussian process with realizations that can be differentiated $k$ times. The form of the covariance function depends on the choice of $d$ and $k$. Wendland covariance functions have compact support, which is a particularly useful property because we can exploit the sparsity of the the corresponding covariance matrices. In this study we use Wendland covariance functions to describe the temporal component of transient displacements. Therefore, we only require that $d=1$ and $k=1$. The corresponding Wendland covariance function is 
\begin{equation}\label{eq:Wendland}
C(x,x') = \alpha^2\left(1 - \frac{|x - x'|}{\beta}\right)^3_+ \left(\frac{3|x - x'|}{\beta} + 1\right), \ \ \ x,x' \in \mathbb{R}^1,
\end{equation}
where
\begin{equation}
(x)_+ = 
\begin{cases}
x, \ \ \ x > 0 \\
0, \ \ \ \mathrm{otherwise}.
\end{cases}
\end{equation}

We next consider the covariance function which describes a first-order Gauss-Markov (FOGM) process. A FOGM process is a solution to the stochastic differential equation
\begin{equation}
\dot{u}(x) + \alpha u(x) = \beta w(x), \ \ \ x,x' \in \mathbb{R}^1,
\end{equation}
where $w(x)$ is white noise with unit variance.  The solution is a Gaussian process with zero mean and covariance
% This needs to be scaled to match my work
\begin{equation}\label{eq:FOGM}
C(x,x') = \frac{\beta^2}{2\alpha}\exp\left(-\alpha|x - x'|\right), \ \ \ x,x' \in \mathbb{R}^1. 
\end{equation}
FOGM processes are isotropic and realizations are not differentiable.  The FOGM model has been used to describe temporally correlated noise in EDM data \citep{Langbein2004} and GNSS data \citep[e.g.,][]{Langbein2008}. 

One last covariance function which is worth mentioning, even though we do not use it in this paper, is the periodic covariance function \citep{Mackay1998}, 
\begin{equation}\label{eq:Periodic}
C(x,x') = \alpha^2 \exp\left(\frac{-\sin(\frac{\pi}{\lambda} |x - x'|)^2}{2 \beta^2} \right), \ \ \ x,x' \in \mathbb{R}^1.
\end{equation}
The periodic covariance function describes an isotropic Gaussian process with realizations that have period $\lambda$.  The length-scale of features within each period is controlled by $\beta$. In terms of GNSS data, a periodic Gaussian process can be used to describe seasonal deformation. The more common method of treating seasonal deformation is to model it as a linear combination of annual and semi-annual sinusoids \citep[e.g.,][]{Dong2002}. We believe there is potential to use periodic Gaussian processes to explore the statistical properties of seasonal signals; however, that is outside the scope of this paper.   

Brownian motion and integrated Brownian motion are two Gaussian processes which are frequently used in the geodetic literature.  Brownian motion, which has zero mean and covariance function
\begin{equation}\label{eq:BM}
C(x,x') =\alpha^2 \min(x,x'), \ \ \ x,x' \in \mathbb{R}^1 \ \mathrm{and} \ \ x,x' \geq 0, 
\end{equation} 
is commonly used to describe noise resulting from the instability of geodetic monuments \citep[e.g.,][]{Wyatt1982,Wyatt1989,Langbein1997}. Integrated Brownian motion, which has zero mean and covariance function
\begin{align}\label{eq:IBM}
C(x,x') &= \int_0^x \int_0^{x'} \alpha^2 \min(u,u') \,du'\,du \\
        &= \frac{\alpha^2}{2}\min(x,x')^2 \left(\max(x,x') - \frac{1}{3}\min(x,x')\right), \ \ \ x,x' \in \mathbb{R}^1 \ \mathrm{and} \ \ x,x' \geq 0,
\end{align}
has been used as a nonparametric model for the time dependence of geophysical signals \citep[e.g.,][]{Segall1997,McGuire2003,Ohtani2010,Hines2016}. It should be noted that Brownian motion and integrated Brownian motion have a reference time at which the Gaussian process is exactly zero. For some geophysical signals, such as postseismic deformation, it is reasonable to have such a reference time. On the other hand, if there is no sense of a start time for the geophysical process, then Brownian motion or integrated Brownian motion may not be appropriate, and one of the isoptropic Gaussian processes described above should be used.        

\subsection{Conditioning}
In this section we describe how to condition the prior for transient displacements, $u$, with GNSS observations, $\bm{d}_*$, to form a posterior estimate of transient displacements, $\hat{u} = u | \bm{d}_*$. We will assume that an appropriate covariance functions and corresponding hyperparameters for $X$, $T$, and $C_\epsilon$ have already been chosen. If $\lambda$ is kept finite, then we can follow \citet{Rasmussen2006} to find that $\hat{u}$ is distributed as $\mathcal{N}(\mu_{\hat{u}},C_{\hat{u}})$, where
\begin{equation}\label{eq:PosteriorMean}
\mu_{\hat{u}}(z) = C_u(z,\bm{y})\bm{C_d}^{-1}\bm{d}_*
\end{equation}    
and
\begin{equation}\label{eq:PosteriorCov}
C_{\hat{u}}(z,z') = C_u(z,\bm{y})\bm{C_d}^{-1}C_u(\bm{y},z').
\end{equation}
However, we are interested in the limit as $\lambda \to \infty$, and the form for eq. (\ref{eq:PosteriorMean}) and eq. (\ref{eq:PosteriorCov}) is not suitable for evaluating this limit. We can use the partitioned matrix inversion identity \citep[e.g.,][]{Press2007} to rewrite eq. (\ref{eq:PosteriorMean}) and eq. (\ref{eq:PosteriorCov}) as
 \begin{equation}\label{eq:PosteriorMean2}
\mu_{\hat{u}}(z) =
\left[ 
\begin{array}{cc}
C_u(z,\bm{y}) & \bm{0} \\
\end{array}
\right]
\left[
\begin{array}{cc}
C_u(\bm{y},\bm{y}) + C_\epsilon(\bm{y},\bm{y}) & \bm{P} \\
\bm{P}^T  & -\lambda^{-2} \bm{I} \\
\end{array}
\right]^{-1}
\left[
\begin{array}{c}
\bm{d}_* \\
\bm{0} \\
\end{array}
\right]
\end{equation}    
and
\begin{equation}\label{eq:PosteriorCov2}
C_{\hat{u}}(z,z') = 
C_u(z,z') - 
\left[ 
\begin{array}{cc}
C_u(z,\bm{y}) & \bm{0} \\
\end{array}
\right]
\left[
\begin{array}{cc}
C_u(\bm{y},\bm{y}) + C_\epsilon(\bm{y},\bm{y}) & \bm{P} \\
\bm{P}^T  & -\lambda^{-2} \bm{I} \\
\end{array}
\right]^{-1}
\left[
\begin{array}{c}
C_u(\bm{y},z') \\
\bm{0} \\
\end{array}
\right].
\end{equation}
Taking the limit as $\lambda \to \infty$, we get the solution for the mean and covariance of $\hat{u}$,
 \begin{equation}\label{eq:PosteriorMean3}
\mu_{\hat{u}}(z) =
\left[ 
\begin{array}{cc}
C_u(z,\bm{y}) & \bm{0} \\
\end{array}
\right]
\left[
\begin{array}{cc}
C_u(\bm{y},\bm{y}) + C_\epsilon(\bm{y},\bm{y}) & \bm{P} \\
\bm{P}^T  & \bm{0} \\
\end{array}
\right]^{-1}
\left[
\begin{array}{c}
\bm{d}_* \\
\bm{0} \\
\end{array}
\right]
\end{equation}    
and
\begin{equation}\label{eq:PosteriorCov3}
C_{\hat{u}}(z,z') = 
C_u(z,z') - 
\left[ 
\begin{array}{cc}
C_u(z,\bm{y}) & \bm{0} \\
\end{array}
\right]
\left[
\begin{array}{cc}
C_u(\bm{y},\bm{y}) + C_\epsilon(\bm{y},\bm{y}) & \bm{P} \\
\bm{P}^T  & \bm{0} \\
\end{array}
\right]^{-1}
\left[
\begin{array}{c}
C_u(\bm{y},z') \\
\bm{0} \\
\end{array}
\right].
\end{equation}
which allows us to evaluate the limit  evaluate the limit 
and we consider the GNSS observations $\bm{d}_*$ to be a realization of $\bm{d}$. Furthermore, we The random vector $\bm{d}$ is distributed as $\bm{d} \sim \mathcal{N}(\bar{\bm{d}},\bm{C_d})$, where 
\begin{equation}
\bm{d}
\end{equation}



We consider the column vector of GNSS observations, $\bm{d}_*$, to be realizations of $d_{ij}$ at the positions and times in $\bm{y}$ (i.e, $\bm{d}_* = [d_{ij}(\omega_*)]^T_{(x_i,t_j) \in \bm{y}}$). We want to find the posterior estimate of transient displacements, $u | \bm{d}_*$, which incorporates our prior and the GNSS observations.

        
Once we have chosen covariance functions and corresponding hyperparameters for $X$, $T$, and $C_d$, we then condition our prior Gaussian process, $u$, with the observations $d_*$ to form a posterior estimate of transient displacements, $u|d_*$. $d_*$ is a realization of the 
   
Whichever the Gaussian processes describing transient displacements, $u$, and noise in the GNSS data, $\epsilon$, have covariance functions which         
     
     
     
Optimal Hyperparameters

Conditioning the GP

Differentiation, scaling and addition to get strain     

\subsection{Time Depenent Strain Rate in Cascadia}\label{sec:ApplicationsCascadia}

BACKGROUND

\citet{Dragert2001} first discovered slow slip events

Slow slip event depths from \citet{Dragert2001}, \citet{Wech2009}, \citet{Schmidt2010}, \citet{Bartlow2011} show slip concentrated at depths from 30 to 50 km detph.
 
Interseismic locking depths from \citet{Fluck1997}, \citet{Murray2000}, \citet{McCaffrey2007} and \citet{McCaffrey2013}, \citet{Burgette2009}, \citet{schmalzle2014} are consistent with a full locking down to about 20 km.

%Studies which simultaneously looked at intersesimic and ets are \citet{Holtkamp2010} and \citet{Schmalzle2014}
Studies which simultaneously modeled interseismic and ets are \citet{Holtkamp2010} and \citet{schmalzle2014}

METHOD

We use GPS displacement time series to make daily estimates of strain rates from 2010-01-01 to 2016-07-01 in the Pacific Northwest.  Our method consists of two distinct steps; we temporally smooth and differentiate the displacement time series for each station, and then we spatially smooth and differentiate the velocity field for each day.  We temporally smooth the GPS displacements with the method described in \ref{sec:Filter}, and we treat days with missing data as observations with infinite uncertainty. As noted above, this is effectively equivalent to fitting a smoothing spline to each time series, which can also be efficiently done with a Kalman filtering strategy \citep{Kohn1987}.  We chose a cutoff frequency of ZZZ, which is high enough to acurately describe deformation during a slow slip event.  Spatial smoothing is done with the RBF-FD filter and differentiation to get the strain rates was done with the RBF-FD scheme.  We picked a cutoff frequency of XXX for smoothing.

\section{Discussion and Conclusion}\label{sec:Discussion}
% discuss potential applications for slip models

% discuss how we remove errors like reference frame and seasonals

% discuss how this can be used for tikhonov regularization

% we do not interpolate the strain field because it may introduce spurious artifacts Baxter2011

% Discuss similarities with PCA used in Dong2006 and common mode error by Wdowinski1997
% note that these errors are due to long wavelength features which get removed in strain calculations!!!
% see strain method by almendinger2007

% mention the scec geodetic transient exercise Lohman2013 and references therein

% Note that segalls 2016 paper mentions the gap between interseismic and sse

% mention howell2016, who said some crap about verticals, mention Hammond2016 so said more sensible crap about verticals

% note that this can be used for smoothing verticals, and compare it with burgette2009

% change the notation for stencil size or smoothness order because they are both n. use p for smoothness order


The material presented in this paper is primarily focused on GPS data; however, we speculate that the RBF-FD scheme can be of particular use in denoising borehole strain meter (BSM) data.  The Plate Boundary Observatory has deployed X BSMs along the Western United States.  BSM data contains low frequency drift resulting from relaxation of the borehole \citep{Gladwin1987}, which can obscure the geophysical signal of interest.  We suggest that the RBF-FD scheme may be useful in denoising BSM data.  Since the RBF-FD scheme provides a straight-forward mapping from GPS displacements to strain at any target locations, it is possible to use GPS derived strains as \textit{a priori} information for strain at BSM sites. GPS derived strains could then aid in discerning tectonic signal from noise in BSM data.

Additional uses for strain: transient detection, prior for strain meters,  

Additional potential applications of the RBF-FD method: regularizing inverse problems, 

% cite eric calais for triangulation strain

\bibliographystyle{apalike}
\bibliography{mybib}  
 
\end{document}
